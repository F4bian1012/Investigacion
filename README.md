# InvestigaciÃ³n TinyML - Arduino Portenta H7

Este proyecto sigue una arquitectura **MLOps** rigurosa adaptada para Sistemas Embebidos (TinyML). El objetivo es garantizar la reproducibilidad de los experimentos, la trazabilidad de los modelos y una clara separaciÃ³n entre el entrenamiento (Python) y el despliegue (C++).

## ðŸ“‚ FilosofÃ­a de la Estructura de Directorios

La organizaciÃ³n de carpetas ha sido diseÃ±ada siguiendo las mejores prÃ¡cticas de la industria:

### 1. `data/` - El ciclo de vida de los datos
Separamos los datos en tres estados inmutables para evitar corrupciÃ³n y fugas de informaciÃ³n:
- **`raw/`**: Datos crudos tal como se obtuvieron del sensor o fuente. **Nunca se sobreescriben.**
- **`processed/`**: Datos limpios, normalizados y listos para entrar al modelo.
- **`augmented/`**: Versiones generadas artificialmente para robustecer el entrenamiento (ruido aÃ±adido, cambios de tono, etc.).

### 2. `models/` - GestiÃ³n de Artefactos
- **`checkpoints/`**: Guardamos los modelos "pesados" de entrenamiento (formato `.keras` o `.h5`). Estos contienen el estado completo del optimizador.
- **`tflite/`**: AquÃ­ residen Ãºnicamente los modelos cuantizados y optimizados para el microcontrolador (`.tflite`) y sus conversiones a arreglos de C (`model.h`).

### 3. `src/` vs `deployment/`
- **`src/`**: Contiene todo el cÃ³digo Python para la "ciencia" del proyecto (entrenamiento, evaluaciÃ³n, scripts de utilidad). Es el entorno del Data Scientist.
- **`deployment/arduino_project/`**: Contiene el cÃ³digo fuente C++ final que se cargarÃ¡ en la Portenta H7. Es el entorno del Ingeniero Embebido. Mantener esto separado evita conflictos de dependencias entre Python y C++.

### 4. `logs/` y `config/`
- **`logs/`**: Almacena grÃ¡ficas de pÃ©rdidas (loss curves), mÃ©tricas de precisiÃ³n y registros de experimentos. Fundamental para comparar quÃ© iteraciÃ³n del modelo funciona mejor.
- **`config/`**: Archivos de configuraciÃ³n o hiperparÃ¡metros.

## ðŸš€ CÃ³mo empezar

1. Instala las dependencias de Python:
   ```bash
   pip install -r requirements.txt
   ```
2. Realiza tus experimentos en `notebooks/` o scripts en `src/`.
3. Una vez tengas un modelo entrenado, expÃ³rtalo a `models/tflite/`.
4. Copia el arreglo C generado a `deployment/arduino_project/` para compilarlo en Arduino IDE.

## ðŸ› ï¸ Scripts de OptimizaciÃ³n (NUEVO)

Se han aÃ±adido scripts avanzados para aplicar tÃ©cnicas de compresiÃ³n de modelos, esenciales para hardware limitado:

### 1. `src/pruning_techniques.py` (Poda)
Este script aplica diferentes estrategias para reducir conexiones neuronales no esenciales:
- **Poda de Decaimiento PolinÃ³mico**: Aumenta gradualmente la dispersiÃ³n durante el entrenamiento.
- **DispersiÃ³n Constante**: Mantiene un nivel fijo de "ceros" en los pesos.
- **Poda por Capas**: Aplica diferentes agresividades de poda segÃºn el tipo de capa (Conv2D vs Dense).

**Uso:**
```bash
python3 src/pruning_techniques.py
```

### 2. `src/quantization_techniques.py` (CuantizaciÃ³n)
Este script demuestra cÃ³mo reducir la precisiÃ³n numÃ©rica de los pesos y activaciones para ahorrar memoria (Flash/RAM) y acelerar la inferencia:
- **Rango DinÃ¡mico**: Pesos int8, activaciones float32.
- **Enteros Completo (Float Fallback)**: Intenta int8, usa float si es necesario.
- **Enteros Completo (Integer Only)**: Obligatorio para MCUs sencillos (Portenta, ESP32).
- **Float16**: Reduce a la mitad el tamaÃ±o, Ãºtil para GPUs.
- **QAT (Training Aware)**: Simula la cuantizaciÃ³n durante el entrenamiento para recuperar precisiÃ³n.

**Uso:**
```bash
python3 src/quantization_techniques.py
```
> **Nota:** Requiere instalar `tensorflow-model-optimization`.

